{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/bitcoin-forecast/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/bitcoin-forecast'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Cleaned Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2650, 18)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>Volume BTC</th>\n",
              "      <th>Volume USD</th>\n",
              "      <th>price mean</th>\n",
              "      <th>upper shadow</th>\n",
              "      <th>lower shadow</th>\n",
              "      <th>spread</th>\n",
              "      <th>trade</th>\n",
              "      <th>10 period SMA</th>\n",
              "      <th>50 period SMA</th>\n",
              "      <th>100 period SMA</th>\n",
              "      <th>12EMA</th>\n",
              "      <th>26EMA</th>\n",
              "      <th>MACD</th>\n",
              "      <th>buy/sell</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-11-29</th>\n",
              "      <td>376.42</td>\n",
              "      <td>386.60</td>\n",
              "      <td>372.25</td>\n",
              "      <td>376.72</td>\n",
              "      <td>2746157.05</td>\n",
              "      <td>7245.19</td>\n",
              "      <td>377.9975</td>\n",
              "      <td>9.88</td>\n",
              "      <td>4.17</td>\n",
              "      <td>14.35</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>376.347692</td>\n",
              "      <td>376.312593</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-11-30</th>\n",
              "      <td>376.57</td>\n",
              "      <td>381.99</td>\n",
              "      <td>373.32</td>\n",
              "      <td>373.34</td>\n",
              "      <td>1145566.61</td>\n",
              "      <td>3046.33</td>\n",
              "      <td>376.3050</td>\n",
              "      <td>5.42</td>\n",
              "      <td>0.02</td>\n",
              "      <td>8.67</td>\n",
              "      <td>-3.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>375.884970</td>\n",
              "      <td>376.092401</td>\n",
              "      <td>-0.207430</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-12-01</th>\n",
              "      <td>376.40</td>\n",
              "      <td>382.31</td>\n",
              "      <td>373.03</td>\n",
              "      <td>378.39</td>\n",
              "      <td>2520662.37</td>\n",
              "      <td>6660.56</td>\n",
              "      <td>377.5325</td>\n",
              "      <td>3.92</td>\n",
              "      <td>3.37</td>\n",
              "      <td>9.28</td>\n",
              "      <td>1.99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>376.270360</td>\n",
              "      <td>376.262593</td>\n",
              "      <td>0.007766</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-12-02</th>\n",
              "      <td>378.39</td>\n",
              "      <td>382.86</td>\n",
              "      <td>375.23</td>\n",
              "      <td>379.25</td>\n",
              "      <td>2593576.46</td>\n",
              "      <td>6832.53</td>\n",
              "      <td>378.9325</td>\n",
              "      <td>3.61</td>\n",
              "      <td>3.16</td>\n",
              "      <td>7.63</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>376.728766</td>\n",
              "      <td>376.483883</td>\n",
              "      <td>0.244883</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-12-03</th>\n",
              "      <td>379.25</td>\n",
              "      <td>383.00</td>\n",
              "      <td>374.23</td>\n",
              "      <td>376.67</td>\n",
              "      <td>2998357.92</td>\n",
              "      <td>7908.29</td>\n",
              "      <td>378.2875</td>\n",
              "      <td>3.75</td>\n",
              "      <td>2.44</td>\n",
              "      <td>8.77</td>\n",
              "      <td>-2.58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>376.719725</td>\n",
              "      <td>376.497669</td>\n",
              "      <td>0.222056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              open    high     low   close  Volume BTC  Volume USD  \\\n",
              "date                                                                 \n",
              "2014-11-29  376.42  386.60  372.25  376.72  2746157.05     7245.19   \n",
              "2014-11-30  376.57  381.99  373.32  373.34  1145566.61     3046.33   \n",
              "2014-12-01  376.40  382.31  373.03  378.39  2520662.37     6660.56   \n",
              "2014-12-02  378.39  382.86  375.23  379.25  2593576.46     6832.53   \n",
              "2014-12-03  379.25  383.00  374.23  376.67  2998357.92     7908.29   \n",
              "\n",
              "            price mean  upper shadow  lower shadow  spread  trade  \\\n",
              "date                                                                \n",
              "2014-11-29    377.9975          9.88          4.17   14.35   0.30   \n",
              "2014-11-30    376.3050          5.42          0.02    8.67  -3.23   \n",
              "2014-12-01    377.5325          3.92          3.37    9.28   1.99   \n",
              "2014-12-02    378.9325          3.61          3.16    7.63   0.86   \n",
              "2014-12-03    378.2875          3.75          2.44    8.77  -2.58   \n",
              "\n",
              "            10 period SMA  50 period SMA  100 period SMA       12EMA  \\\n",
              "date                                                                   \n",
              "2014-11-29            0.0            0.0             0.0  376.347692   \n",
              "2014-11-30            0.0            0.0             0.0  375.884970   \n",
              "2014-12-01            0.0            0.0             0.0  376.270360   \n",
              "2014-12-02            0.0            0.0             0.0  376.728766   \n",
              "2014-12-03            0.0            0.0             0.0  376.719725   \n",
              "\n",
              "                 26EMA      MACD  buy/sell  \n",
              "date                                        \n",
              "2014-11-29  376.312593  0.035100         1  \n",
              "2014-11-30  376.092401 -0.207430         0  \n",
              "2014-12-01  376.262593  0.007766         1  \n",
              "2014-12-02  376.483883  0.244883         1  \n",
              "2014-12-03  376.497669  0.222056         0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/cleaned/BTCAugmented.csv\", index_col='date', parse_dates=True))\n",
        "\n",
        "print(df.shape)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Step 2: ML Pipeline with all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ML pipeline for Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;numerical_transformation&#x27;,\n",
              "                 YeoJohnsonTransformer(variables=[&#x27;open&#x27;, &#x27;high&#x27;, &#x27;low&#x27;,\n",
              "                                                  &#x27;close&#x27;, &#x27;Volume BTC&#x27;,\n",
              "                                                  &#x27;Volume USD&#x27;, &#x27;price mean&#x27;,\n",
              "                                                  &#x27;upper shadow&#x27;,\n",
              "                                                  &#x27;lower shadow&#x27;, &#x27;spread&#x27;,\n",
              "                                                  &#x27;10 period SMA&#x27;,\n",
              "                                                  &#x27;50 period SMA&#x27;,\n",
              "                                                  &#x27;100 period SMA&#x27;, &#x27;12EMA&#x27;,\n",
              "                                                  &#x27;26EMA&#x27;])),\n",
              "                (&#x27;SmartCorrelatedSelection&#x27;,\n",
              "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
              "                                          selection_method=&#x27;variance&#x27;,\n",
              "                                          threshold=0.6))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;numerical_transformation&#x27;,\n",
              "                 YeoJohnsonTransformer(variables=[&#x27;open&#x27;, &#x27;high&#x27;, &#x27;low&#x27;,\n",
              "                                                  &#x27;close&#x27;, &#x27;Volume BTC&#x27;,\n",
              "                                                  &#x27;Volume USD&#x27;, &#x27;price mean&#x27;,\n",
              "                                                  &#x27;upper shadow&#x27;,\n",
              "                                                  &#x27;lower shadow&#x27;, &#x27;spread&#x27;,\n",
              "                                                  &#x27;10 period SMA&#x27;,\n",
              "                                                  &#x27;50 period SMA&#x27;,\n",
              "                                                  &#x27;100 period SMA&#x27;, &#x27;12EMA&#x27;,\n",
              "                                                  &#x27;26EMA&#x27;])),\n",
              "                (&#x27;SmartCorrelatedSelection&#x27;,\n",
              "                 SmartCorrelatedSelection(method=&#x27;spearman&#x27;,\n",
              "                                          selection_method=&#x27;variance&#x27;,\n",
              "                                          threshold=0.6))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">YeoJohnsonTransformer</label><div class=\"sk-toggleable__content\"><pre>YeoJohnsonTransformer(variables=[&#x27;open&#x27;, &#x27;high&#x27;, &#x27;low&#x27;, &#x27;close&#x27;, &#x27;Volume BTC&#x27;,\n",
              "                                 &#x27;Volume USD&#x27;, &#x27;price mean&#x27;, &#x27;upper shadow&#x27;,\n",
              "                                 &#x27;lower shadow&#x27;, &#x27;spread&#x27;, &#x27;10 period SMA&#x27;,\n",
              "                                 &#x27;50 period SMA&#x27;, &#x27;100 period SMA&#x27;, &#x27;12EMA&#x27;,\n",
              "                                 &#x27;26EMA&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SmartCorrelatedSelection</label><div class=\"sk-toggleable__content\"><pre>SmartCorrelatedSelection(method=&#x27;spearman&#x27;, selection_method=&#x27;variance&#x27;,\n",
              "                         threshold=0.6)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('numerical_transformation',\n",
              "                 YeoJohnsonTransformer(variables=['open', 'high', 'low',\n",
              "                                                  'close', 'Volume BTC',\n",
              "                                                  'Volume USD', 'price mean',\n",
              "                                                  'upper shadow',\n",
              "                                                  'lower shadow', 'spread',\n",
              "                                                  '10 period SMA',\n",
              "                                                  '50 period SMA',\n",
              "                                                  '100 period SMA', '12EMA',\n",
              "                                                  '26EMA'])),\n",
              "                ('SmartCorrelatedSelection',\n",
              "                 SmartCorrelatedSelection(method='spearman',\n",
              "                                          selection_method='variance',\n",
              "                                          threshold=0.6))])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine import transformation as vt\n",
        "\n",
        "# Feature Engineering\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "\n",
        "\n",
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "    pipeline_base = Pipeline([\n",
        "        ('numerical_transformation', vt.YeoJohnsonTransformer(variables=['open', 'high', 'low', 'close', 'Volume BTC', 'Volume USD', \n",
        "                         'price mean', 'upper shadow', 'lower shadow', \n",
        "                         'spread', '10 period SMA', '50 period SMA', \n",
        "                         '100 period SMA', '12EMA', '26EMA'])),\n",
        "\n",
        "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
        "         method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base\n",
        "\n",
        "\n",
        "PipelineDataCleaningAndFeatureEngineering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ML Pipeline for Modelling and Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "def PipelineClf(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"feat_selection\", SelectFromModel(model)),\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Custom Class for Hyperparameter Optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model = PipelineClf(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, )\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2120, 17) (2120,) (530, 17) (530,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['buy/sell'], axis=1),\n",
        "    df['buy/sell'],\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Handle Target Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2120, 3) (2120,) (530, 3) (530,)\n"
          ]
        }
      ],
      "source": [
        "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
        "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
        "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Train Set Target distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use SMOTE (Synthetic Minority Oversampling TEchnique) to balance Train Set target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2286, 3) (2286,) (530, 3) (530,)\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE(sampling_strategy='minority', random_state=0)\n",
        "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Train Set Target distribution after resampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid Search CV - Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use standard hyperparameters to find most suitable algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LogisticRegression\": {},\n",
        "    \"XGBClassifier\": {},\n",
        "    \"DecisionTreeClassifier\": {},\n",
        "    \"RandomForestClassifier\": {},\n",
        "    \"GradientBoostingClassifier\": {},\n",
        "    \"ExtraTreesClassifier\": {},\n",
        "    \"AdaBoostClassifier\": {},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quick GridSearch CV - Binary Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for LogisticRegression \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for XGBClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for DecisionTreeClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for RandomForestClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for GradientBoostingClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for ExtraTreesClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for AdaBoostClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer, recall_score\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(recall_score, pos_label=1),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.982533</td>\n",
              "      <td>0.991251</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.981636</td>\n",
              "      <td>0.986842</td>\n",
              "      <td>0.006399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.979886</td>\n",
              "      <td>0.986842</td>\n",
              "      <td>0.005903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.979009</td>\n",
              "      <td>0.982533</td>\n",
              "      <td>0.005072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.965066</td>\n",
              "      <td>0.978135</td>\n",
              "      <td>0.986842</td>\n",
              "      <td>0.007293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.965066</td>\n",
              "      <td>0.974634</td>\n",
              "      <td>0.982456</td>\n",
              "      <td>0.005776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    estimator min_score mean_score max_score std_score\n",
              "0          LogisticRegression  0.982533   0.991251       1.0  0.005524\n",
              "1               XGBClassifier  0.969432    0.98426  0.991266  0.008089\n",
              "6          AdaBoostClassifier  0.969432   0.981636  0.986842  0.006399\n",
              "4  GradientBoostingClassifier  0.969432   0.979886  0.986842  0.005903\n",
              "5        ExtraTreesClassifier  0.969432   0.979009  0.982533  0.005072\n",
              "3      RandomForestClassifier  0.965066   0.978135  0.986842  0.007293\n",
              "2      DecisionTreeClassifier  0.965066   0.974634  0.982456  0.005776"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extensive search on the most suitable algorithm to find the best hyperparameter configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Define the models to search\n",
        "models_search = { \n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "# Define hyperparameters for each model\n",
        "params_search = {\n",
        "    \"LogisticRegression\": {\n",
        "        'model__C': [0.01, 0.1, 1, 10],  # Regularization parameter\n",
        "        'model__penalty': ['l2'],  # Common penalty for logistic regression\n",
        "        'model__solver': ['lbfgs']  # Standard solver, suitable for small to medium datasets\n",
        "    },\n",
        "    \"XGBClassifier\": {\n",
        "        'model__learning_rate': [0.1, 0.01, 0.001],\n",
        "        'model__max_depth': [3, 10, None],\n",
        "        'model__n_estimators': [50, 100, 200]  # Number of trees\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extensive GridSearch CV - Binary Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for LogisticRegression \n",
            "\n",
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "\n",
            "Running GridSearchCV for XGBClassifier \n",
            "\n",
            "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import recall_score, make_scorer\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(recall_score, pos_label=1),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>model__C</th>\n",
              "      <th>model__penalty</th>\n",
              "      <th>model__solver</th>\n",
              "      <th>model__learning_rate</th>\n",
              "      <th>model__max_depth</th>\n",
              "      <th>model__n_estimators</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.978166</td>\n",
              "      <td>0.992128</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007512</td>\n",
              "      <td>0.1</td>\n",
              "      <td>l2</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.982533</td>\n",
              "      <td>0.991251</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005524</td>\n",
              "      <td>1</td>\n",
              "      <td>l2</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.982533</td>\n",
              "      <td>0.989504</td>\n",
              "      <td>0.995633</td>\n",
              "      <td>0.004447</td>\n",
              "      <td>10</td>\n",
              "      <td>l2</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.973799</td>\n",
              "      <td>0.985134</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.006525</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.973799</td>\n",
              "      <td>0.985134</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.006525</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.973799</td>\n",
              "      <td>0.985134</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.006525</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>3</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>None</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>None</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>None</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>None</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>None</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>None</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>None</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>None</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>None</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.969432</td>\n",
              "      <td>0.98426</td>\n",
              "      <td>0.991266</td>\n",
              "      <td>0.008089</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.89083</td>\n",
              "      <td>0.975538</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.042388</td>\n",
              "      <td>0.01</td>\n",
              "      <td>l2</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             estimator min_score mean_score max_score std_score model__C  \\\n",
              "1   LogisticRegression  0.978166   0.992128       1.0  0.007512      0.1   \n",
              "2   LogisticRegression  0.982533   0.991251       1.0  0.005524        1   \n",
              "3   LogisticRegression  0.982533   0.989504  0.995633  0.004447       10   \n",
              "4        XGBClassifier  0.973799   0.985134  0.991266  0.006525      NaN   \n",
              "5        XGBClassifier  0.973799   0.985134  0.991266  0.006525      NaN   \n",
              "6        XGBClassifier  0.973799   0.985134  0.991266  0.006525      NaN   \n",
              "15       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "24       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "21       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "22       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "23       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "27       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "25       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "26       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "19       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "28       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "29       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "20       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "30       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "18       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "17       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "16       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "14       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "13       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "12       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "11       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "10       XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "9        XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "8        XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "7        XGBClassifier  0.969432    0.98426  0.991266  0.008089      NaN   \n",
              "0   LogisticRegression   0.89083   0.975538       1.0  0.042388     0.01   \n",
              "\n",
              "   model__penalty model__solver model__learning_rate model__max_depth  \\\n",
              "1              l2         lbfgs                  NaN              NaN   \n",
              "2              l2         lbfgs                  NaN              NaN   \n",
              "3              l2         lbfgs                  NaN              NaN   \n",
              "4             NaN           NaN                  0.1                3   \n",
              "5             NaN           NaN                  0.1                3   \n",
              "6             NaN           NaN                  0.1                3   \n",
              "15            NaN           NaN                 0.01                3   \n",
              "24            NaN           NaN                0.001                3   \n",
              "21            NaN           NaN                 0.01             None   \n",
              "22            NaN           NaN                0.001                3   \n",
              "23            NaN           NaN                0.001                3   \n",
              "27            NaN           NaN                0.001               10   \n",
              "25            NaN           NaN                0.001               10   \n",
              "26            NaN           NaN                0.001               10   \n",
              "19            NaN           NaN                 0.01             None   \n",
              "28            NaN           NaN                0.001             None   \n",
              "29            NaN           NaN                0.001             None   \n",
              "20            NaN           NaN                 0.01             None   \n",
              "30            NaN           NaN                0.001             None   \n",
              "18            NaN           NaN                 0.01               10   \n",
              "17            NaN           NaN                 0.01               10   \n",
              "16            NaN           NaN                 0.01               10   \n",
              "14            NaN           NaN                 0.01                3   \n",
              "13            NaN           NaN                 0.01                3   \n",
              "12            NaN           NaN                  0.1             None   \n",
              "11            NaN           NaN                  0.1             None   \n",
              "10            NaN           NaN                  0.1             None   \n",
              "9             NaN           NaN                  0.1               10   \n",
              "8             NaN           NaN                  0.1               10   \n",
              "7             NaN           NaN                  0.1               10   \n",
              "0              l2         lbfgs                  NaN              NaN   \n",
              "\n",
              "   model__n_estimators  \n",
              "1                  NaN  \n",
              "2                  NaN  \n",
              "3                  NaN  \n",
              "4                   50  \n",
              "5                  100  \n",
              "6                  200  \n",
              "15                 200  \n",
              "24                 200  \n",
              "21                 200  \n",
              "22                  50  \n",
              "23                 100  \n",
              "27                 200  \n",
              "25                  50  \n",
              "26                 100  \n",
              "19                  50  \n",
              "28                  50  \n",
              "29                 100  \n",
              "20                 100  \n",
              "30                 200  \n",
              "18                 200  \n",
              "17                 100  \n",
              "16                  50  \n",
              "14                 100  \n",
              "13                  50  \n",
              "12                 200  \n",
              "11                 100  \n",
              "10                  50  \n",
              "9                  200  \n",
              "8                  100  \n",
              "7                   50  \n",
              "0                  NaN  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get best model name programmatically"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LogisticRegression'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameters for best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model__C': 0.1, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the best clf pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;feat_selection&#x27;,\n",
              "                 SelectFromModel(estimator=LogisticRegression(random_state=0))),\n",
              "                (&#x27;model&#x27;, LogisticRegression(C=0.1, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;feat_selection&#x27;,\n",
              "                 SelectFromModel(estimator=LogisticRegression(random_state=0))),\n",
              "                (&#x27;model&#x27;, LogisticRegression(C=0.1, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">feat_selection: SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=LogisticRegression(random_state=0))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, random_state=0)</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('feat_selection',\n",
              "                 SelectFromModel(estimator=LogisticRegression(random_state=0))),\n",
              "                ('model', LogisticRegression(C=0.1, random_state=0))])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
        "pipeline_clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assess feature importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Volume USD</th>\n",
              "      <th>trade</th>\n",
              "      <th>MACD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.297683</td>\n",
              "      <td>130.95</td>\n",
              "      <td>-514.335331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.710361</td>\n",
              "      <td>-1065.08</td>\n",
              "      <td>-29.981253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33.325335</td>\n",
              "      <td>-2045.20</td>\n",
              "      <td>-902.492367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Volume USD    trade        MACD\n",
              "0   28.297683   130.95 -514.335331\n",
              "1   31.710361 -1065.08  -29.981253\n",
              "2   33.325335 -2045.20 -902.492367"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Per-column arrays must each be 1-dimensional",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create DataFrame to display feature importance\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_feature_importance \u001b[38;5;241m=\u001b[39m (\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpipeline_clf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat_selection\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_clf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# re-assign best_features order\u001b[39;00m\n\u001b[1;32m      9\u001b[0m best_features \u001b[38;5;241m=\u001b[39m df_feature_importance[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/internals/construction.py:661\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    659\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
          ]
        }
      ],
      "source": [
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "    'Feature': X_train.columns[pipeline_clf['feat_selection'].get_support()],\n",
        "    'Importance': pipeline_clf['model'].coef_})\n",
        "    .sort_values(by='Importance', ascending=False)\n",
        ")\n",
        "\n",
        "# re-assign best_features order\n",
        "best_features = df_feature_importance['Feature'].to_list()\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate Pipeline on Train and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
        "\n",
        "    prediction = pipeline.predict(X)\n",
        "\n",
        "    print('---  Confusion Matrix  ---')\n",
        "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
        "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
        "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
        "          ))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print('---  Classification Report  ---')\n",
        "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
        "\n",
        "\n",
        "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
        "    print(\"#### Train Set #### \\n\")\n",
        "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
        "\n",
        "    print(\"#### Test Set ####\\n\")\n",
        "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual Sell Actual Buy\n",
            "Prediction Sell        1018          5\n",
            "Prediction Buy          125       1138\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Sell       1.00      0.89      0.94      1143\n",
            "         Buy       0.90      1.00      0.95      1143\n",
            "\n",
            "    accuracy                           0.94      2286\n",
            "   macro avg       0.95      0.94      0.94      2286\n",
            "weighted avg       0.95      0.94      0.94      2286\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual Sell Actual Buy\n",
            "Prediction Sell         231          0\n",
            "Prediction Buy           21        278\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Sell       1.00      0.92      0.96       252\n",
            "         Buy       0.93      1.00      0.96       278\n",
            "\n",
            "    accuracy                           0.96       530\n",
            "   macro avg       0.96      0.96      0.96       530\n",
            "weighted avg       0.96      0.96      0.96       530\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=pipeline_clf,\n",
        "                label_map= ['Sell', 'Buy'] \n",
        "                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
